{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py    \n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from pylab import savefig\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= pd.read_hdf('train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>61430</th>\n",
       "      <th>61431</th>\n",
       "      <th>61432</th>\n",
       "      <th>61433</th>\n",
       "      <th>61434</th>\n",
       "      <th>61435</th>\n",
       "      <th>61436</th>\n",
       "      <th>61437</th>\n",
       "      <th>61438</th>\n",
       "      <th>61439</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041259</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>0.023887</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>0.041259</td>\n",
       "      <td>0.045602</td>\n",
       "      <td>0.038001</td>\n",
       "      <td>0.030401</td>\n",
       "      <td>0.032573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034744</td>\n",
       "      <td>-0.007600</td>\n",
       "      <td>-0.003257</td>\n",
       "      <td>0.065145</td>\n",
       "      <td>0.047773</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.031487</td>\n",
       "      <td>0.096632</td>\n",
       "      <td>0.077089</td>\n",
       "      <td>0.040173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.211722</td>\n",
       "      <td>-0.264924</td>\n",
       "      <td>-0.274696</td>\n",
       "      <td>-0.236694</td>\n",
       "      <td>-0.156349</td>\n",
       "      <td>-0.059716</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.046687</td>\n",
       "      <td>0.153091</td>\n",
       "      <td>0.281210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260581</td>\n",
       "      <td>-0.004343</td>\n",
       "      <td>-0.241037</td>\n",
       "      <td>-0.636252</td>\n",
       "      <td>-0.953292</td>\n",
       "      <td>-0.980436</td>\n",
       "      <td>-0.846888</td>\n",
       "      <td>-0.838202</td>\n",
       "      <td>-0.880546</td>\n",
       "      <td>-0.739398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214105</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.136640</td>\n",
       "      <td>0.013987</td>\n",
       "      <td>-0.038733</td>\n",
       "      <td>-0.015063</td>\n",
       "      <td>-0.111894</td>\n",
       "      <td>-0.104363</td>\n",
       "      <td>0.047340</td>\n",
       "      <td>-0.054871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040884</td>\n",
       "      <td>0.375490</td>\n",
       "      <td>0.699337</td>\n",
       "      <td>0.965085</td>\n",
       "      <td>1.086662</td>\n",
       "      <td>1.132926</td>\n",
       "      <td>1.279249</td>\n",
       "      <td>1.296464</td>\n",
       "      <td>0.937112</td>\n",
       "      <td>0.451879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.154837</td>\n",
       "      <td>-0.127768</td>\n",
       "      <td>-0.217638</td>\n",
       "      <td>-0.284770</td>\n",
       "      <td>-0.299929</td>\n",
       "      <td>-0.270694</td>\n",
       "      <td>-0.077960</td>\n",
       "      <td>0.092036</td>\n",
       "      <td>0.076877</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.286936</td>\n",
       "      <td>-0.171079</td>\n",
       "      <td>-0.036814</td>\n",
       "      <td>-0.024904</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.140761</td>\n",
       "      <td>-0.011911</td>\n",
       "      <td>-0.173244</td>\n",
       "      <td>-0.063884</td>\n",
       "      <td>0.081208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.022780</td>\n",
       "      <td>-0.916376</td>\n",
       "      <td>-0.676425</td>\n",
       "      <td>-0.461445</td>\n",
       "      <td>-0.330069</td>\n",
       "      <td>-0.122690</td>\n",
       "      <td>0.178064</td>\n",
       "      <td>0.489675</td>\n",
       "      <td>0.799115</td>\n",
       "      <td>0.931577</td>\n",
       "      <td>...</td>\n",
       "      <td>1.009751</td>\n",
       "      <td>1.134613</td>\n",
       "      <td>0.836030</td>\n",
       "      <td>0.479903</td>\n",
       "      <td>0.109661</td>\n",
       "      <td>-0.285553</td>\n",
       "      <td>-0.628651</td>\n",
       "      <td>-0.916376</td>\n",
       "      <td>-1.010837</td>\n",
       "      <td>-0.804544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1672</th>\n",
       "      <td>-0.063989</td>\n",
       "      <td>0.017228</td>\n",
       "      <td>0.015997</td>\n",
       "      <td>-0.321177</td>\n",
       "      <td>-0.503300</td>\n",
       "      <td>-0.535295</td>\n",
       "      <td>-0.562367</td>\n",
       "      <td>-0.600515</td>\n",
       "      <td>-0.573442</td>\n",
       "      <td>-0.317485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.121826</td>\n",
       "      <td>-0.134131</td>\n",
       "      <td>-0.111981</td>\n",
       "      <td>-0.057836</td>\n",
       "      <td>-0.073834</td>\n",
       "      <td>-0.125517</td>\n",
       "      <td>-0.082448</td>\n",
       "      <td>-0.036917</td>\n",
       "      <td>-0.114442</td>\n",
       "      <td>-0.183354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>0.993037</td>\n",
       "      <td>0.726052</td>\n",
       "      <td>0.341885</td>\n",
       "      <td>0.286314</td>\n",
       "      <td>0.535177</td>\n",
       "      <td>0.605245</td>\n",
       "      <td>0.198124</td>\n",
       "      <td>-0.375711</td>\n",
       "      <td>-0.579875</td>\n",
       "      <td>-0.495310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038658</td>\n",
       "      <td>0.188460</td>\n",
       "      <td>0.273025</td>\n",
       "      <td>0.045907</td>\n",
       "      <td>-0.108727</td>\n",
       "      <td>0.072484</td>\n",
       "      <td>0.415577</td>\n",
       "      <td>0.356382</td>\n",
       "      <td>-0.096646</td>\n",
       "      <td>-0.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674</th>\n",
       "      <td>0.570550</td>\n",
       "      <td>0.253578</td>\n",
       "      <td>-0.193841</td>\n",
       "      <td>-0.502279</td>\n",
       "      <td>-0.657108</td>\n",
       "      <td>-0.838757</td>\n",
       "      <td>-0.971642</td>\n",
       "      <td>-0.881427</td>\n",
       "      <td>-0.700996</td>\n",
       "      <td>-0.520566</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.146295</td>\n",
       "      <td>0.128008</td>\n",
       "      <td>0.162143</td>\n",
       "      <td>0.018287</td>\n",
       "      <td>-0.017068</td>\n",
       "      <td>0.087777</td>\n",
       "      <td>0.062175</td>\n",
       "      <td>-0.041450</td>\n",
       "      <td>-0.140199</td>\n",
       "      <td>-0.247482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>0.630677</td>\n",
       "      <td>0.605010</td>\n",
       "      <td>0.477897</td>\n",
       "      <td>0.155225</td>\n",
       "      <td>-0.441229</td>\n",
       "      <td>-0.679566</td>\n",
       "      <td>-0.515786</td>\n",
       "      <td>-0.424118</td>\n",
       "      <td>-0.183336</td>\n",
       "      <td>0.394784</td>\n",
       "      <td>...</td>\n",
       "      <td>0.229781</td>\n",
       "      <td>-0.041556</td>\n",
       "      <td>-0.176003</td>\n",
       "      <td>-0.301894</td>\n",
       "      <td>-0.177225</td>\n",
       "      <td>0.033001</td>\n",
       "      <td>0.025667</td>\n",
       "      <td>0.088001</td>\n",
       "      <td>0.206559</td>\n",
       "      <td>0.003667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1676</th>\n",
       "      <td>0.083910</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.044423</td>\n",
       "      <td>0.080208</td>\n",
       "      <td>0.097483</td>\n",
       "      <td>0.077740</td>\n",
       "      <td>0.038253</td>\n",
       "      <td>0.033317</td>\n",
       "      <td>0.061698</td>\n",
       "      <td>0.075272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081442</td>\n",
       "      <td>0.081442</td>\n",
       "      <td>0.078974</td>\n",
       "      <td>0.080208</td>\n",
       "      <td>0.086378</td>\n",
       "      <td>0.088846</td>\n",
       "      <td>0.085144</td>\n",
       "      <td>0.081442</td>\n",
       "      <td>0.083910</td>\n",
       "      <td>0.087612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1677 rows × 61440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6      \\\n",
       "0     0.041259  0.041259  0.032573  0.023887  0.029315  0.041259  0.045602   \n",
       "1    -0.211722 -0.264924 -0.274696 -0.236694 -0.156349 -0.059716  0.005429   \n",
       "2     0.214105  0.154930  0.136640  0.013987 -0.038733 -0.015063 -0.111894   \n",
       "3    -0.154837 -0.127768 -0.217638 -0.284770 -0.299929 -0.270694 -0.077960   \n",
       "4    -1.022780 -0.916376 -0.676425 -0.461445 -0.330069 -0.122690  0.178064   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1672 -0.063989  0.017228  0.015997 -0.321177 -0.503300 -0.535295 -0.562367   \n",
       "1673  0.993037  0.726052  0.341885  0.286314  0.535177  0.605245  0.198124   \n",
       "1674  0.570550  0.253578 -0.193841 -0.502279 -0.657108 -0.838757 -0.971642   \n",
       "1675  0.630677  0.605010  0.477897  0.155225 -0.441229 -0.679566 -0.515786   \n",
       "1676  0.083910  0.044423  0.044423  0.080208  0.097483  0.077740  0.038253   \n",
       "\n",
       "         7         8         9      ...     61430     61431     61432  \\\n",
       "0     0.038001  0.030401  0.032573  ...  0.034744 -0.007600 -0.003257   \n",
       "1     0.046687  0.153091  0.281210  ...  0.260581 -0.004343 -0.241037   \n",
       "2    -0.104363  0.047340 -0.054871  ...  0.040884  0.375490  0.699337   \n",
       "3     0.092036  0.076877  0.154837  ... -0.286936 -0.171079 -0.036814   \n",
       "4     0.489675  0.799115  0.931577  ...  1.009751  1.134613  0.836030   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1672 -0.600515 -0.573442 -0.317485  ... -0.121826 -0.134131 -0.111981   \n",
       "1673 -0.375711 -0.579875 -0.495310  ...  0.038658  0.188460  0.273025   \n",
       "1674 -0.881427 -0.700996 -0.520566  ... -0.146295  0.128008  0.162143   \n",
       "1675 -0.424118 -0.183336  0.394784  ...  0.229781 -0.041556 -0.176003   \n",
       "1676  0.033317  0.061698  0.075272  ...  0.081442  0.081442  0.078974   \n",
       "\n",
       "         61433     61434     61435     61436     61437     61438     61439  \n",
       "0     0.065145  0.047773 -0.009772  0.031487  0.096632  0.077089  0.040173  \n",
       "1    -0.636252 -0.953292 -0.980436 -0.846888 -0.838202 -0.880546 -0.739398  \n",
       "2     0.965085  1.086662  1.132926  1.279249  1.296464  0.937112  0.451879  \n",
       "3    -0.024904  0.031400  0.140761 -0.011911 -0.173244 -0.063884  0.081208  \n",
       "4     0.479903  0.109661 -0.285553 -0.628651 -0.916376 -1.010837 -0.804544  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1672 -0.057836 -0.073834 -0.125517 -0.082448 -0.036917 -0.114442 -0.183354  \n",
       "1673  0.045907 -0.108727  0.072484  0.415577  0.356382 -0.096646 -0.280273  \n",
       "1674  0.018287 -0.017068  0.087777  0.062175 -0.041450 -0.140199 -0.247482  \n",
       "1675 -0.301894 -0.177225  0.033001  0.025667  0.088001  0.206559  0.003667  \n",
       "1676  0.080208  0.086378  0.088846  0.085144  0.081442  0.083910  0.087612  \n",
       "\n",
       "[1677 rows x 61440 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1677, 61440)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04125864,  0.04125864,  0.03257261, ...,  0.09663208,\n",
       "         0.07708851,  0.04017289],\n",
       "       [-0.21172198, -0.26492391, -0.2746957 , ..., -0.83820187,\n",
       "        -0.88054628, -0.73939828],\n",
       "       [ 0.21410477,  0.1549301 ,  0.13663973, ...,  1.29646364,\n",
       "         0.93711189,  0.45187944],\n",
       "       ...,\n",
       "       [ 0.57054995,  0.25357776, -0.19384069, ..., -0.04145021,\n",
       "        -0.14019924, -0.24748214],\n",
       "       [ 0.63067681,  0.60500973,  0.47789657, ...,  0.08800142,\n",
       "         0.20655888,  0.00366673],\n",
       "       [ 0.08390965,  0.04442275,  0.04442275, ...,  0.08144171,\n",
       "         0.08390965,  0.08761154]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 1.00001628e-03, 2.00003255e-03, ...,\n",
       "       6.14380000e+01, 6.14390000e+01, 6.14400000e+01])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temps=np.linspace(0,61440/1000,61440)\n",
    "temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x182e601dcc8>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(temps,t[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "\n",
    "from statsmodels.robust import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1677, 61440) (1677, 61440)\n",
      "102910729 17857979\n"
     ]
    }
   ],
   "source": [
    "wf = \"haar\"\n",
    "\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for x in t :\n",
    "    #Apply wavelet decomposition\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IsolationForest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py:237: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (1677, 61440) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-9efdd2ca6a9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbehaviour\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'new'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCoeff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_hdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'validation.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\iforest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    286\u001b[0m         super()._fit(X, y, max_samples,\n\u001b[0;32m    287\u001b[0m                      \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m                      sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbehaviour\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'old'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[0;32m    377\u001b[0m                 \u001b[0mtotal_n_estimators\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m                 verbose=self.verbose)\n\u001b[1;32m--> 379\u001b[1;33m             for i in range(n_jobs))\n\u001b[0m\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1003\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\bagging.py\u001b[0m in \u001b[0;36m_parallel_build_estimators\u001b[1;34m(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnot_indices_mask\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1155\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (1677, 61440) and data type float32"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = IsolationForest(behaviour='new')\n",
    "clf.fit(Coeff)\n",
    "v=pd.read_hdf('validation.hdf5')\n",
    "v=pd.DataFrame(v)\n",
    "res=clf.predict(v)\n",
    "for i in range(len(res)) : \n",
    "    if res[i]==1 : \n",
    "        res[i]=0\n",
    "    else :\n",
    "        res[i]= 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=pd.DataFrame(res.T)\n",
    "res.to_csv('IsolationForest_Wavelet7.csv',sep = ';', mode = 'w',index=True,header=['anomaly'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
