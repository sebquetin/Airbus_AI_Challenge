{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py    \n",
    "import numpy as np  \n",
    "import pandas as pd\n",
    "from pylab import savefig\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from pylab import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ACP\n",
    "import sklearn.decomposition as sd\n",
    "import sklearn.preprocessing as sp\n",
    "\n",
    "# Hierarchical clustering\n",
    "import scipy.cluster.hierarchy as sch\n",
    "# LOF\n",
    "import sklearn.neighbors as sn\n",
    "# Isolation Forest\n",
    "import sklearn.ensemble as se\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "sb.set_style(\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= pd.read_hdf('/home/joevin/Bureau/train.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=pd.DataFrame(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t=array(f.iloc[4])\n",
    "temps=np.linspace(0,61440/1000,61440)\n",
    "plot(temps,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier=np.fft.fft(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features= np.zeros((1677,5))\n",
    "for i in range(1677) : \n",
    "    features[i,0]=np.mean(fourier[i])\n",
    "    features[i,1] = np.var(fourier[i])\n",
    "    features[i,2] = np.median(fourier[i])\n",
    "    features[i,3] = np.real(stats.kurtosis(fourier[i],bias=False))\n",
    "    features[i,4] = np.real(stats.skew(fourier[i],bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "from pywt import wavedec\n",
    "\n",
    "from statsmodels.robust import mad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = \"haar\"\n",
    "f=np.array(f)\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for i in range(1677) :\n",
    "    #Apply wavelet decomposition\n",
    "    x=f[i]\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresw= np.zeros((1677,10))\n",
    "for i in range(1677) : \n",
    "    featuresw[i,0] = np.mean(Coeff[i])\n",
    "    featuresw[i,1] = np.var(Coeff[i])\n",
    "    featuresw[i,2] = np.median(Coeff[i])\n",
    "    featuresw[i,3] = np.real(stats.kurtosis(Coeff[i],bias=False))\n",
    "    featuresw[i,4] = np.real(stats.skew(Coeff[i],bias=False))\n",
    "    featuresw[i,5] = np.mean(TCoeff[i])\n",
    "    featuresw[i,6] = np.var(TCoeff[i])\n",
    "    featuresw[i,7] = np.median(TCoeff[i])\n",
    "    featuresw[i,8] = np.real(stats.kurtosis(TCoeff[i],bias=False))\n",
    "    featuresw[i,9] = np.real(stats.skew(TCoeff[i],bias=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresw= np.zeros((1677,10))\n",
    "features= np.zeros((1677,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=np.zeros((1677,15))\n",
    "feat[:,0:5]=features\n",
    "feat[:,5:15]=featuresw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acp = sd.PCA()\n",
    "acp_features = acp.fit_transform(sp.scale(feat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One class svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label=np.zeros(1677)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm as ssvm\n",
    "OCS = ssvm.OneClassSVM(kernel=\"rbf\", nu=0.05)\n",
    "\n",
    "OCS.fit(acp_features)\n",
    "pred = OCS.predict(acp_features)\n",
    "\n",
    "CT_svm = pd.DataFrame(list(zip(pred,Y_label)), columns=[\"pred\",\"Anomaly\"])\n",
    "display(pd.crosstab(CT_svm.pred, CT_svm.Anomaly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sur validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=pd.read_hdf('/home/joevin/Bureau/validation.hdf5')\n",
    "v=pd.DataFrame(v)\n",
    "fourier=np.fft.fft(v)\n",
    "features= np.zeros((1677,5))\n",
    "for i in range(1677) : \n",
    "    features[i,0]=np.mean(fourier[i])\n",
    "    features[i,1] = np.var(fourier[i])\n",
    "    features[i,2] = np.median(fourier[i])\n",
    "    features[i,3] = np.real(stats.kurtosis(fourier[i],bias=False))\n",
    "    features[i,4] = np.real(stats.skew(fourier[i],bias=False))\n",
    "wf = \"haar\"\n",
    "v=np.array(v)\n",
    "Coeff = []\n",
    "TCoeff = []\n",
    "for i in range(1677) :\n",
    "    #Apply wavelet decomposition\n",
    "    x=v[i]\n",
    "    coeffs = pywt.wavedec(x,wf,level=7)\n",
    "    coeffs_flatten = np.hstack(coeffs)\n",
    "    Coeff.append(coeffs_flatten)\n",
    "    \n",
    "    # Compute universal Threshold http://jseabold.net/blog/2012/02/23/wavelet-regression-in-python/\n",
    "    sigma = mad(coeffs[-1])\n",
    "    uthresh = sigma*np.sqrt(2*np.log(128))\n",
    "    # Apply Threshold on 4 last levels\n",
    "    coeffs_thresh = [pywt.threshold(c, uthresh, mode=\"hard\") if i<=3 else c for i,c in enumerate(coeffs[::-1])]\n",
    "    coeffs_thresh_flatten = np.hstack(coeffs_thresh[::-1])\n",
    "    TCoeff.append(coeffs_thresh_flatten)\n",
    "    \n",
    "Coeff = np.array(Coeff)\n",
    "TCoeff = np.array(TCoeff)\n",
    "print(Coeff.shape, TCoeff.shape)\n",
    "print(np.sum(Coeff!=0), np.sum(TCoeff!=0))\n",
    "\n",
    "featuresw= np.zeros((1677,10))\n",
    "for i in range(1677) : \n",
    "    featuresw[i,0] = np.mean(Coeff[i])\n",
    "    featuresw[i,1] = np.var(Coeff[i])\n",
    "    featuresw[i,2] = np.median(Coeff[i])\n",
    "    featuresw[i,3] = np.real(stats.kurtosis(Coeff[i],bias=False))\n",
    "    featuresw[i,4] = np.real(stats.skew(Coeff[i],bias=False))\n",
    "    featuresw[i,5] = np.mean(TCoeff[i])\n",
    "    featuresw[i,6] = np.var(TCoeff[i])\n",
    "    featuresw[i,7] = np.median(TCoeff[i])\n",
    "    featuresw[i,8] = np.real(stats.kurtosis(TCoeff[i],bias=False))\n",
    "    featuresw[i,9] = np.real(stats.skew(TCoeff[i],bias=False))\n",
    "    \n",
    "feat=np.zeros((1677,15))\n",
    "feat[:,0:5]=features\n",
    "feat[:,5:15]=featuresw\n",
    "\n",
    "acp = sd.PCA()\n",
    "acp_features = acp.fit_transform(sp.scale(feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=OCS.predict(v)\n",
    "for i in range(len(res)) : \n",
    "    if res[i]==1 : \n",
    "        res[i]=0\n",
    "    else :\n",
    "        res[i]= 1 \n",
    "res=pd.DataFrame(res.T)\n",
    "res.to_csv('IA.csv',sep = ';', mode = 'w',index=True,header=['seqID;anomaly'])\n",
    "sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
